{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c46361-b82e-4f6e-bca8-2502bec0c8c7",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db6242-6bbd-405d-b6a4-983d79dcd958",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch\n",
    "opencv-python\n",
    "Pillow\n",
    "plotly\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3494919-f8b0-4794-a468-46da14ec0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Text, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    xmin: int\n",
    "    ymin: int\n",
    "    xmax: int\n",
    "    ymax: int\n",
    "\n",
    "@dataclass\n",
    "class DetectionResult:\n",
    "    score: float\n",
    "    label: str\n",
    "    box: BoundingBox\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, detection_dict: dict) -> 'DetectionResult':\n",
    "        return cls(\n",
    "            score=detection_dict['score'],\n",
    "            label=detection_dict['label'],\n",
    "            box=BoundingBox(\n",
    "                xmin=detection_dict['box']['xmin'],\n",
    "                ymin=detection_dict['box']['ymin'],\n",
    "                xmax=detection_dict['box']['xmax'],\n",
    "                ymax=detection_dict['box']['ymax']\n",
    "            )\n",
    "        )\n",
    "\n",
    "def load_image(image_str: str) -> Image.Image:\n",
    "    if image_str.startswith(\"http\"):\n",
    "        image = Image.open(requests.get(image_str, stream=True).raw).convert(\"RGB\")\n",
    "    else:\n",
    "        image = Image.open(image_str).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "def detect(image: Image.Image, labels: List[str], threshold: float = 0.3) -> List[DetectionResult]:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    detector_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "    object_detector = pipeline(model=detector_id, task=\"zero-shot-object-detection\", device=device)\n",
    "\n",
    "    labels = [label if label.endswith(\".\") else label + \".\" for label in labels]\n",
    "    results = object_detector(image, candidate_labels=labels, threshold=threshold)\n",
    "    results = [DetectionResult.from_dict(result) for result in results]\n",
    "\n",
    "    return results\n",
    "\n",
    "class AIModelApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"AI Model Image Segmentation\")\n",
    "\n",
    "        self.image_label = tk.Label(master, text=\"Upload an Image:\")\n",
    "        self.image_label.pack()\n",
    "\n",
    "        self.upload_button = tk.Button(master, text=\"Upload Image\", command=self.upload_image)\n",
    "        self.upload_button.pack()\n",
    "\n",
    "        self.prompt_label = tk.Label(master, text=\"Enter labels (comma-separated):\")\n",
    "        self.prompt_label.pack()\n",
    "\n",
    "        self.prompt_entry = Text(master, height=5, width=50)\n",
    "        self.prompt_entry.pack()\n",
    "\n",
    "        self.submit_button = tk.Button(master, text=\"Submit\", command=self.process_image)\n",
    "        self.submit_button.pack()\n",
    "\n",
    "        self.delete_button = tk.Button(master, text=\"Delete Selected Boxes\", command=self.delete_selected_boxes)\n",
    "        self.delete_button.pack()\n",
    "\n",
    "        self.result_label = tk.Label(master, text=\"\")\n",
    "        self.result_label.pack()\n",
    "\n",
    "        self.display_label = tk.Label(master)\n",
    "        self.display_label.pack()\n",
    "\n",
    "        self.image_path = \"\"\n",
    "        self.detections = []\n",
    "        self.selected_boxes = []\n",
    "        self.offsets = []\n",
    "\n",
    "    def upload_image(self):\n",
    "        self.image_path = filedialog.askopenfilename()\n",
    "        if self.image_path:\n",
    "            image = Image.open(self.image_path)\n",
    "            image.thumbnail((300, 300))\n",
    "            self.display_image(image)\n",
    "\n",
    "    def display_image(self, image: Image.Image):\n",
    "        max_width, max_height = 600, 600\n",
    "        image.thumbnail((max_width, max_height), Image.BICUBIC)\n",
    "        self.image_display = ImageTk.PhotoImage(image)\n",
    "        self.display_label.config(image=self.image_display)\n",
    "        self.display_label.image = self.image_display\n",
    "        self.bind_mouse_events()\n",
    "\n",
    "    def bind_mouse_events(self):\n",
    "        self.display_label.bind(\"<ButtonPress-1>\", self.on_mouse_click)\n",
    "        self.display_label.bind(\"<B1-Motion>\", self.on_mouse_drag)\n",
    "        self.display_label.bind(\"<ButtonRelease-1>\", self.on_button_release)\n",
    "\n",
    "    def on_mouse_click(self, event):\n",
    "        x, y = event.x, event.y\n",
    "        for detection in self.detections:\n",
    "            box = detection.box\n",
    "            # Check if click is near the annotation\n",
    "            if box.xmin <= x <= box.xmax and box.ymin <= y <= box.ymax:\n",
    "                if detection not in self.selected_boxes:\n",
    "                    self.selected_boxes.append(detection)\n",
    "                    self.offsets.append((x - box.xmin, y - box.ymin))\n",
    "                break\n",
    "        self.redraw_image()\n",
    "\n",
    "    def on_mouse_drag(self, event):\n",
    "        for index, detection in enumerate(self.selected_boxes):\n",
    "            box = detection.box\n",
    "            offset_x, offset_y = self.offsets[index]\n",
    "            box.xmin = event.x - offset_x\n",
    "            box.xmax = box.xmin + (box.xmax - box.xmin)\n",
    "            box.ymin = event.y - offset_y\n",
    "            box.ymax = box.ymin + (box.ymax - box.ymin)\n",
    "        self.redraw_image()\n",
    "\n",
    "    def on_button_release(self, event):\n",
    "        pass  # No action needed on button release for multiple selection\n",
    "\n",
    "    def delete_selected_boxes(self):\n",
    "        if self.selected_boxes:\n",
    "            for box in self.selected_boxes:\n",
    "                self.detections.remove(box)\n",
    "            self.selected_boxes = []\n",
    "            self.offsets = []\n",
    "            self.redraw_image()\n",
    "        else:\n",
    "            messagebox.showinfo(\"Info\", \"No bounding boxes selected.\")\n",
    "\n",
    "    def redraw_image(self):\n",
    "        image = load_image(self.image_path)\n",
    "        annotated_image = self.draw_detections(image, self.detections)\n",
    "        self.display_image(annotated_image)\n",
    "\n",
    "    def draw_detections(self, image: Image.Image, detections: List[DetectionResult]) -> Image.Image:\n",
    "        image_cv2 = np.array(image)\n",
    "        image_cv2 = cv2.cvtColor(image_cv2, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        for detection in detections:\n",
    "            box = detection.box\n",
    "            color = (0, 255, 0)  # Green for bounding boxes\n",
    "            cv2.rectangle(image_cv2, (box.xmin, box.ymin), (box.xmax, box.ymax), color, 2)\n",
    "            cv2.putText(image_cv2, f'{detection.label}: {detection.score:.2f}', \n",
    "                        (box.xmin, box.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        return Image.fromarray(cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    def process_image(self):\n",
    "        labels_input = self.prompt_entry.get(\"1.0\", tk.END).strip()\n",
    "        labels = [label.strip() + '.' for label in labels_input.split(',') if label.strip()]\n",
    "\n",
    "        if self.image_path and labels:\n",
    "            self.detections = detect(load_image(self.image_path), labels)\n",
    "            annotated_image = self.draw_detections(load_image(self.image_path), self.detections)\n",
    "            self.display_image(annotated_image)\n",
    "            self.result_label.config(text=\"Processing complete. Click on annotations to select.\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Please upload an image and enter labels.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AIModelApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
